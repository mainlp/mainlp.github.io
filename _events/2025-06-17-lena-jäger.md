---
title: "Simulating Reading: Generative Modeling of Eye Movements and Its Applications in NLP and Psycholinguistics"
abstract: "The way our eyes move while reading provides valuable insights into both the reader’s cognitive processes and the properties of the text. In particular, eye-tracking-while-reading data has not only been considered the gold-standard methodology in psycholinguistic reading research for the past decades, but, more recently, has also been shown to be beneficial in various technological applications, such as enhancing and interpreting language models or inferring a reader’s characteristics. However, these applications often rely on large-scale, data-driven models, which demand extensive eye-tracking datasets that are challenging to obtain due to the resource-intensive nature of data collection. Another challenge is that for many use cases, such as gaze-augmented language modeling, no eyetracking recordings are available at deployment time. In this talk, I will demonstrate how we can tackle these two challenges by simulating human-like eye movements using recent machine learning techniques. I will discuss how these synthetic gaze data can be used not only for technological applications, such as gaze-enhanced NLP, but also to support psycholinguistic research—for example, by facilitating stimulus piloting or performing power analyses during study design. <br/> From a modeling perspective, eye-tracking data presents a unique challenge: it is a spatio-temporal, multimodal signal where a dynamic gaze sequence interacts in complex ways with a static linguistic input—the text. This interaction is shaped by linguistic and non-linguistic properties of the text, individual reader characteristics, and task-specific factors. While many earlier approaches simplify this complexity by aggregating over one of the modalities, I will present two alternative modeling strategies that preserve the full richness of the data: (1) a dual-encoder architecture that aligns gaze and text representations through cross-attention, and (2) a diffusion-based model that generates scanpaths conditioned on a given text. In sum, I will show how we can overcome two of the key bottlenecks in eye movement research—data scarcity and the unavailability of gaze recordings at deployment time—by developing generative models capable of simulating human-like gaze patterns on any given stimulus text."
speaker: Lena Jäger, <br/>
    Associate Professor, Department of Computational Linguistics, University of Zurich
bio: "With an interdisciplinary background in cognitive science and computer science, Lena Jäger's research interests lie at the intersection of experimental and computational psycholinguistics, machine learning and NLP. The focus of her current research is twofold. On the one hand, she is interested in the development of methods for leveraging eye tracking data for a broad range of language-related use cases, such as gaze-augmented language modeling, the inference of an individual's reading comprehension or foreign language skills, or the development of generative models to simulate human eye movements in reading. On the other hand, she investigates individual differences in language processing, with a specific focus on statistical and methodological questions. She is currently leading the EU COST Action <a href=\"https://multipleye.eu\">MultiplEYE</a>, an international network of researchers focusing on collecting and using multilingual eye-tracking-while-reading data for computational psycholinguistics and NLP."
website: https://www.cl.uzh.ch/en/research-groups/digital-linguistics/people/group-leader/jaeger.html
time: June 17, 2025; 14:15–15:30
location: LMU main building (Geschwister-Scholl-Platz 1), room E&nbsp;216
roomfinder: https://www.lmu.de/raumfinder/#/building/bw0000/map?room=001902343_
img: assets/img/lena-jäger.jpg
imgalt: Portrait of Lena Jäger
imgside: right
anchor: 2025-06-17-lena-jäger
---

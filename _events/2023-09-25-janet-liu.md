---
title: "The Pivotal Role of Genres: Insights from English RST Parsing and Abstractive Summarization "
abstract: Text exhibits significant variations across types such as news articles, academic papers, social media posts, vlogs, and more. Recognizing the importance of genre and using data from diverse genres in training can enable NLP models to generalize and perform effectively across diverse textual contexts. While previous work has studied the role of genre in tasks and linguistic phenomena such as dependency parsing (Müller-Eberstein et al., EMNLP 2021; Müller-Eberstein et al., TLT-SyntaxFest 2021), NLI (Nangia et al., RepEval 2017), and lexical semantics (Kober et al., COLING 2020), in this talk I will present our work that emphasizes the importance of genre diversity in the case of RST parsing and summarization.<br/>I will first discuss our results from the English RST parsing task that a heterogeneous training regime is critical for stable and generalizable RST models, regardless of parser architectures [1,3].  Then, I will present GUMSum [2], a carefully crafted dataset of English summaries in 12 written and spoken genres for evaluation of abstractive summarization. This work emphasizes the complexities of producing high-quality summaries across genres, where impressive models like GPT-3 fall short of human performance, highlighting the need to consider genre-specific guidelines for crafting accurate and faithful summaries. Together, we hope our findings and resources can not only raise awareness and help level the playing field across text-types, demographics, and domains in English but also offer insights that can benefit the same or analogous tasks and phenomena in other languages.<br/>[1] <a href="https://aclanthology.org/2023.eacl-main.227/">https://aclanthology.org/2023.eacl-main.227/</a><br/>[2] <a href="https://aclanthology.org/2023.findings-acl.593/">https://aclanthology.org/2023.findings-acl.593/</a><br/>[3] <a href="https://aclanthology.org/2023.law-1.17/">https://aclanthology.org/2023.law-1.17/</a>
speaker: Janet Liu<br/>
    PhD candidate, Georgetown University
bio: Yang Janet Liu (she/her/hers, go by Janet) is a PhD Candidate in Computational Linguistics in the Department of Linguistics at Georgetown University where she is advised by Amir Zeldes, PhD and works on computational and corpus-based approaches to discourse-level linguistic phenomena (e.g., discourse relations and relation signaling) and their applications such as summarization. Specifically, her research focuses on the generalizability of discourse understanding and parsing in Rhetorical Structure Theory (RST). She co-organized the <a href="https://sites.google.com/georgetown.edu/disrpt2021">2021</a> and <a href="https://sites.google.com/view/disrpt2023/">2023</a> DISRPT Shared Task on Discourse Segmentation, Connective and Relation Identification across Formalisms. She has been a reviewer for the main *ACL venues (ACL, EACL, NAACL, AACL), SIGDIAL, as well as the Dialogue and Discourse journal etc., and is an Area Chair of the Discourse and Pragmatics track at EMNLP 2023. Previously, she did internships at Spotify (2021, 2023) and Alexa AI at Amazon (2020).
website: https://janetlauyeung.github.io/ 
time: September 25, 2023; 10:30–11:30
location: Akademiestr. 7, room 218A (meeting room)
roomfinder: https://mainlp.github.io/contact/
img: assets/img/janet.png
imgalt: Portrait of Janet Liu
imgside: right
anchor: 2023-09-25-janet-liu
---